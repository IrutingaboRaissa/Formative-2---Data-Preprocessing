{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b019e14c",
   "metadata": {},
   "source": [
    "# Facial Recognition System\n",
    "## Formative 2 - Data Preprocessing Assignment - Part 2\n",
    "\n",
    "This notebook implements a complete facial recognition system for user authentication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11619d",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5a1df",
   "metadata": {},
   "source": [
    "## Step 2: Load Images\n",
    "\n",
    "Load all team member images from the images folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "IMAGE_DIR = 'images'\n",
    "MODEL_DIR = 'models'\n",
    "FEATURE_DIR = 'features'\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(FEATURE_DIR, exist_ok=True)\n",
    "\n",
    "# Load all images from the images folder\n",
    "images_data = []\n",
    "\n",
    "if os.path.exists(IMAGE_DIR):\n",
    "    for img_file in os.listdir(IMAGE_DIR):\n",
    "        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(IMAGE_DIR, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Extract member info from filename\n",
    "                # Assuming filenames contain member identifiers\n",
    "                if 'IMG_9631' in img_file or 'IMG_9632' in img_file or 'IMG_9633' in img_file:\n",
    "                    member = 'Member1'\n",
    "                elif 'e9f9bfbe' in img_file or '5a5539bd' in img_file or 'eb9bdc7c' in img_file:\n",
    "                    member = 'Member2'\n",
    "                elif '4272da32' in img_file or 'bdc12d05' in img_file or 'c4f0e73e' in img_file:\n",
    "                    member = 'Member3'\n",
    "                elif 'f19c6775' in img_file or '3459b16c' in img_file or 'e1f95694' in img_file:\n",
    "                    member = 'Member4'\n",
    "                else:\n",
    "                    member = 'Unknown'\n",
    "                \n",
    "                images_data.append({\n",
    "                    'path': img_path,\n",
    "                    'member': member,\n",
    "                    'image': img_rgb,\n",
    "                    'filename': img_file\n",
    "                })\n",
    "\n",
    "df_images = pd.DataFrame(images_data)\n",
    "print(f\"Loaded {len(df_images)} images\")\n",
    "print(f\"Members found: {df_images['member'].unique()}\")\n",
    "print(f\"\\nImages per member:\")\n",
    "print(df_images['member'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835b0d55",
   "metadata": {},
   "source": [
    "## Step 3: Display Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first image from each member\n",
    "members = df_images['member'].unique()\n",
    "n_members = len(members)\n",
    "\n",
    "fig, axes = plt.subplots(1, n_members, figsize=(15, 5))\n",
    "if n_members == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, member in enumerate(members):\n",
    "    subset = df_images[df_images['member'] == member]\n",
    "    if len(subset) > 0:\n",
    "        img = subset.iloc[0]['image']\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(member)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b8e39",
   "metadata": {},
   "source": [
    "## Step 4: Image Augmentation\n",
    "\n",
    "Apply multiple augmentations to increase dataset size and improve model robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img):\n",
    "    \"\"\"\n",
    "    Apply various augmentations to an image.\n",
    "    Returns list of (augmentation_name, augmented_image) tuples.\n",
    "    \"\"\"\n",
    "    augmented = []\n",
    "    height, width = img.shape[:2]\n",
    "    center = (width // 2, height // 2)\n",
    "    \n",
    "    # Original\n",
    "    augmented.append(('original', img))\n",
    "    \n",
    "    # Rotation +15 degrees\n",
    "    M = cv2.getRotationMatrix2D(center, 15, 1.0)\n",
    "    rotated_pos = cv2.warpAffine(img, M, (width, height))\n",
    "    augmented.append(('rotated_15', rotated_pos))\n",
    "    \n",
    "    # Rotation -15 degrees\n",
    "    M = cv2.getRotationMatrix2D(center, -15, 1.0)\n",
    "    rotated_neg = cv2.warpAffine(img, M, (width, height))\n",
    "    augmented.append(('rotated_-15', rotated_neg))\n",
    "    \n",
    "    # Horizontal flip\n",
    "    flipped = cv2.flip(img, 1)\n",
    "    augmented.append(('flipped', flipped))\n",
    "    \n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray_rgb = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    augmented.append(('grayscale', gray_rgb))\n",
    "    \n",
    "    # Brightness increase\n",
    "    bright = cv2.convertScaleAbs(img, alpha=1.2, beta=30)\n",
    "    augmented.append(('brightness_up', bright))\n",
    "    \n",
    "    # Brightness decrease\n",
    "    dark = cv2.convertScaleAbs(img, alpha=0.8, beta=-30)\n",
    "    augmented.append(('brightness_down', dark))\n",
    "    \n",
    "    # Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    augmented.append(('blurred', blurred))\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "# Apply augmentation to all images\n",
    "augmented_data = []\n",
    "\n",
    "for idx, row in df_images.iterrows():\n",
    "    augmentations = augment_image(row['image'])\n",
    "    \n",
    "    for aug_type, aug_img in augmentations:\n",
    "        augmented_data.append({\n",
    "            'member': row['member'],\n",
    "            'augmentation': aug_type,\n",
    "            'image': aug_img,\n",
    "            'original_filename': row['filename']\n",
    "        })\n",
    "\n",
    "df_augmented = pd.DataFrame(augmented_data)\n",
    "print(f\"Total images after augmentation: {len(df_augmented)}\")\n",
    "print(f\"Original images: {len(df_images)}\")\n",
    "print(f\"Augmentations per image: {len(df_augmented) // len(df_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c30fd1",
   "metadata": {},
   "source": [
    "## Step 5: Display Augmentation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c35383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show augmentation examples for first member\n",
    "if len(df_augmented) > 0:\n",
    "    first_member = df_augmented['member'].iloc[0]\n",
    "    first_file = df_augmented['original_filename'].iloc[0]\n",
    "    \n",
    "    subset = df_augmented[(df_augmented['member'] == first_member) & \n",
    "                          (df_augmented['original_filename'] == first_file)]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (idx, row) in enumerate(subset.iterrows()):\n",
    "        if i < 8:\n",
    "            axes[i].imshow(row['image'])\n",
    "            axes[i].set_title(row['augmentation'])\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Augmentation Examples - {first_member}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ddef2b",
   "metadata": {},
   "source": [
    "## Step 6: Feature Extraction\n",
    "\n",
    "Extract 217 features from each image including color histograms, HOG descriptors, and statistical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2322dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img, resize_shape=(128, 128)):\n",
    "    \"\"\"\n",
    "    Extract comprehensive features from an image.\n",
    "    Returns a feature vector with 217 features.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Resize for consistency\n",
    "    img_resized = cv2.resize(img, resize_shape)\n",
    "    \n",
    "    # Color histograms for each channel (32 bins x 3 channels = 96 features)\n",
    "    for channel in range(3):\n",
    "        hist = cv2.calcHist([img_resized], [channel], None, [32], [0, 256])\n",
    "        hist = hist.flatten() / hist.sum()\n",
    "        features.extend(hist)\n",
    "    \n",
    "    # Statistical features per channel (5 stats x 3 channels = 15 features)\n",
    "    for channel in range(3):\n",
    "        channel_data = img_resized[:, :, channel]\n",
    "        features.append(np.mean(channel_data))\n",
    "        features.append(np.std(channel_data))\n",
    "        features.append(np.median(channel_data))\n",
    "        features.append(np.min(channel_data))\n",
    "        features.append(np.max(channel_data))\n",
    "    \n",
    "    # Grayscale conversion\n",
    "    gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Edge detection (1 feature)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    features.append(np.sum(edges > 0) / edges.size)\n",
    "    \n",
    "    # HOG features (100 features)\n",
    "    hog_features = hog(gray, orientations=9, pixels_per_cell=(8, 8),\n",
    "                       cells_per_block=(2, 2), visualize=False)\n",
    "    features.extend(hog_features[:100])\n",
    "    \n",
    "    # Texture variance (1 feature)\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    features.append(np.var(laplacian))\n",
    "    \n",
    "    # Additional grayscale statistics (4 features)\n",
    "    features.append(np.mean(gray))\n",
    "    features.append(np.std(gray))\n",
    "    features.append(np.median(gray))\n",
    "    features.append(np.var(gray))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features from all augmented images\n",
    "print(\"Extracting features...\")\n",
    "feature_list = []\n",
    "\n",
    "for idx, row in df_augmented.iterrows():\n",
    "    features = extract_features(row['image'])\n",
    "    \n",
    "    feature_dict = {\n",
    "        'member': row['member'],\n",
    "        'augmentation': row['augmentation']\n",
    "    }\n",
    "    \n",
    "    for i, feat_val in enumerate(features):\n",
    "        feature_dict[f'feature_{i}'] = feat_val\n",
    "    \n",
    "    feature_list.append(feature_dict)\n",
    "\n",
    "df_features = pd.DataFrame(feature_list)\n",
    "print(f\"Feature extraction complete\")\n",
    "print(f\"Dataset shape: {df_features.shape}\")\n",
    "print(f\"Features per image: {len([col for col in df_features.columns if 'feature_' in col])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7e567",
   "metadata": {},
   "source": [
    "## Step 7: Save Features to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c35f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features\n",
    "feature_csv_path = os.path.join(FEATURE_DIR, 'image_features.csv')\n",
    "df_features.to_csv(feature_csv_path, index=False)\n",
    "print(f\"Features saved to: {feature_csv_path}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c55ce",
   "metadata": {},
   "source": [
    "## Step 8: Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5cb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "feature_columns = [col for col in df_features.columns if 'feature_' in col]\n",
    "X = df_features[feature_columns].values\n",
    "y = df_features['member'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of members: {len(label_encoder.classes_)}\")\n",
    "print(f\"Members: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1302bb3",
   "metadata": {},
   "source": [
    "## Step 9: Train Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_rf = rf_model.predict(X_train_scaled)\n",
    "y_pred_test_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "train_acc_rf = accuracy_score(y_train, y_pred_train_rf)\n",
    "test_acc_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "train_f1_rf = f1_score(y_train, y_pred_train_rf, average='weighted')\n",
    "test_f1_rf = f1_score(y_test, y_pred_test_rf, average='weighted')\n",
    "\n",
    "print(f\"\\nRandom Forest Results:\")\n",
    "print(f\"Training Accuracy: {train_acc_rf:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_rf:.4f}\")\n",
    "print(f\"Training F1-Score: {train_f1_rf:.4f}\")\n",
    "print(f\"Test F1-Score: {test_f1_rf:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test_rf, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16833625",
   "metadata": {},
   "source": [
    "## Step 10: Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_lr = lr_model.predict(X_train_scaled)\n",
    "y_pred_test_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "train_acc_lr = accuracy_score(y_train, y_pred_train_lr)\n",
    "test_acc_lr = accuracy_score(y_test, y_pred_test_lr)\n",
    "train_f1_lr = f1_score(y_train, y_pred_train_lr, average='weighted')\n",
    "test_f1_lr = f1_score(y_test, y_pred_test_lr, average='weighted')\n",
    "\n",
    "print(f\"\\nLogistic Regression Results:\")\n",
    "print(f\"Training Accuracy: {train_acc_lr:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_lr:.4f}\")\n",
    "print(f\"Training F1-Score: {train_f1_lr:.4f}\")\n",
    "print(f\"Test F1-Score: {test_f1_lr:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test_lr, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcdc329",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_test_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_,\n",
    "            ax=axes[0])\n",
    "axes[0].set_title('Random Forest')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Logistic Regression\n",
    "cm_lr = confusion_matrix(y_test, y_pred_test_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_,\n",
    "            ax=axes[1])\n",
    "axes[1].set_title('Logistic Regression')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf068a5",
   "metadata": {},
   "source": [
    "## Step 12: Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Logistic Regression'],\n",
    "    'Train Accuracy': [train_acc_rf, train_acc_lr],\n",
    "    'Test Accuracy': [test_acc_rf, test_acc_lr],\n",
    "    'Train F1-Score': [train_f1_rf, train_f1_lr],\n",
    "    'Test F1-Score': [test_f1_rf, test_f1_lr]\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "comparison.plot(x='Model', y=['Train Accuracy', 'Test Accuracy'], \n",
    "               kind='bar', ax=axes[0], rot=0)\n",
    "axes[0].set_title('Accuracy Comparison')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_ylim([0, 1.1])\n",
    "\n",
    "comparison.plot(x='Model', y=['Train F1-Score', 'Test F1-Score'],\n",
    "               kind='bar', ax=axes[1], rot=0, color=['green', 'orange'])\n",
    "axes[1].set_title('F1-Score Comparison')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_ylim([0, 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95bd11c",
   "metadata": {},
   "source": [
    "## Step 13: Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df729b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models and preprocessing objects\n",
    "rf_path = os.path.join(MODEL_DIR, 'face_recognition_rf.pkl')\n",
    "lr_path = os.path.join(MODEL_DIR, 'face_recognition_lr.pkl')\n",
    "scaler_path = os.path.join(MODEL_DIR, 'scaler.pkl')\n",
    "encoder_path = os.path.join(MODEL_DIR, 'label_encoder.pkl')\n",
    "\n",
    "joblib.dump(rf_model, rf_path)\n",
    "joblib.dump(lr_model, lr_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "joblib.dump(label_encoder, encoder_path)\n",
    "\n",
    "print(\"Models saved:\")\n",
    "print(f\"  Random Forest: {rf_path}\")\n",
    "print(f\"  Logistic Regression: {lr_path}\")\n",
    "print(f\"  Scaler: {scaler_path}\")\n",
    "print(f\"  Label Encoder: {encoder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2c87a3",
   "metadata": {},
   "source": [
    "## Step 14: Test Authentication\n",
    "\n",
    "Test the model with sample images from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37051c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_authentication(image, model, scaler, label_encoder, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Test authentication with an image.\n",
    "    \"\"\"\n",
    "    # Extract features\n",
    "    features = extract_features(image)\n",
    "    features_scaled = scaler.transform(features.reshape(1, -1))\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(features_scaled)[0]\n",
    "    probabilities = model.predict_proba(features_scaled)[0]\n",
    "    confidence = probabilities.max()\n",
    "    \n",
    "    if confidence >= threshold:\n",
    "        member_name = label_encoder.inverse_transform([prediction])[0]\n",
    "        return True, member_name, confidence\n",
    "    else:\n",
    "        return False, None, confidence\n",
    "\n",
    "# Test with a few random images from test set\n",
    "test_indices = np.random.choice(len(X_test), min(3, len(X_test)), replace=False)\n",
    "\n",
    "for i, idx in enumerate(test_indices):\n",
    "    test_img = df_augmented.iloc[idx]['image']\n",
    "    true_member = df_augmented.iloc[idx]['member']\n",
    "    \n",
    "    authenticated, predicted_member, confidence = test_authentication(\n",
    "        test_img, rf_model, scaler, label_encoder\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTest {i+1}:\")\n",
    "    print(f\"  True member: {true_member}\")\n",
    "    if authenticated:\n",
    "        print(f\"  Predicted: {predicted_member}\")\n",
    "        print(f\"  Confidence: {confidence:.2%}\")\n",
    "        print(f\"  Status: Authenticated\")\n",
    "    else:\n",
    "        print(f\"  Status: Not authenticated (low confidence: {confidence:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e7eaa",
   "metadata": {},
   "source": [
    "## Step 15: Visual Authentication Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cfecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual test with images\n",
    "test_indices = np.random.choice(len(df_augmented), min(4, len(df_augmented)), replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, idx in enumerate(test_indices):\n",
    "    test_img = df_augmented.iloc[idx]['image']\n",
    "    true_member = df_augmented.iloc[idx]['member']\n",
    "    \n",
    "    authenticated, predicted_member, confidence = test_authentication(\n",
    "        test_img, rf_model, scaler, label_encoder\n",
    "    )\n",
    "    \n",
    "    axes[i].imshow(test_img)\n",
    "    \n",
    "    if authenticated:\n",
    "        title = f\"Authenticated\\n{predicted_member}\\nConfidence: {confidence:.1%}\"\n",
    "        color = 'green' if predicted_member == true_member else 'orange'\n",
    "    else:\n",
    "        title = f\"Not Authenticated\\nConfidence: {confidence:.1%}\"\n",
    "        color = 'red'\n",
    "    \n",
    "    axes[i].set_title(title, color=color, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d9f54",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook completed the following:\n",
    "\n",
    "1. Loaded team member images\n",
    "2. Applied 8 augmentation techniques per image\n",
    "3. Extracted 217 features per image\n",
    "4. Saved features to image_features.csv\n",
    "5. Trained Random Forest and Logistic Regression models\n",
    "6. Evaluated models with accuracy, F1-score, and confusion matrices\n",
    "7. Saved trained models for deployment\n",
    "8. Tested authentication functionality\n",
    "\n",
    "The facial recognition system is ready for integration with voice verification and product recommendation components."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
